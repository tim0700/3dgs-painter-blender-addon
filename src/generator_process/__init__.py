"""
Generator process for 3DGS Painter.

This module provides subprocess-based computation for PyTorch/CUDA operations.
PyTorch is loaded ONLY in the subprocess to avoid TBB DLL conflicts with Blender.

Reference: Dream Textures generator_process/__init__.py
"""

from typing import Callable
from multiprocessing import current_process

from .actor import Actor, is_actor_process
from .future import Future


class RunInSubprocess(Exception):
    """
    Decorators to support running functions that are not defined under the Generator class in its subprocess.
    This is to reduce what would otherwise be duplicate function definitions that logically don't belong to
    the Generator, but require something in its subprocess (such as access to installed dependencies).
    
    Usage:
        @RunInSubprocess
        def my_function():
            import torch  # Only available in subprocess
            return torch.cuda.is_available()
    """

    def __new__(cls, func=None):
        if func is None:
            # support `raise RunInSubprocess`
            return super().__new__(cls)
        return cls.always(func)

    @staticmethod
    def always(func):
        """Always run in subprocess."""
        if is_actor_process:
            return func
        
        def wrapper(*args, **kwargs):
            return NPRGenerator.shared().call(wrapper, *args, **kwargs).result()
        
        RunInSubprocess._copy_attributes(func, wrapper)
        return wrapper

    @staticmethod
    def when(condition: bool | Callable[..., bool]):
        """Run in subprocess when condition is true."""
        if not isinstance(condition, Callable):
            if condition:
                return RunInSubprocess.always
            return lambda x: x
        
        def decorator(func):
            if is_actor_process:
                return func
            
            def wrapper(*args, **kwargs):
                if condition(*args, **kwargs):
                    return NPRGenerator.shared().call(wrapper, *args, **kwargs).result()
                return func(*args, **kwargs)
            
            RunInSubprocess._copy_attributes(func, wrapper)
            return wrapper
        
        return decorator

    @staticmethod
    def when_raised(func):
        """Run in subprocess if RunInSubprocess exception is raised."""
        if is_actor_process:
            return func
        
        def wrapper(*args, **kwargs):
            try:
                return func(*args, **kwargs)
            except RunInSubprocess:
                return NPRGenerator.shared().call(wrapper, *args, **kwargs).result()
        
        RunInSubprocess._copy_attributes(func, wrapper)
        return wrapper

    @staticmethod
    def _copy_attributes(src, dst):
        """Copy function attributes from source to destination."""
        for n in ["__annotations__", "__doc__", "__name__", "__module__", "__qualname__"]:
            if hasattr(src, n):
                setattr(dst, n, getattr(src, n))


class NPRGenerator(Actor):
    """
    The actor used for all background PyTorch/CUDA processes.
    
    All methods defined here (except protected ones) will be executed in the subprocess.
    The subprocess has access to PyTorch, CUDA, gsplat, etc.
    """

    # Import actions from separate modules (executed in subprocess)
    # These will be added as the project progresses
    
    @staticmethod
    def call(func, *args, **kwargs):
        """
        Call a function in the subprocess.
        Used by RunInSubprocess decorator.
        """
        return func(*args, **kwargs)
    
    # ==========================================================================
    # System Info Actions
    # ==========================================================================
    
    def get_torch_info(self) -> dict:
        """
        Get PyTorch and CUDA information.
        
        Returns:
            dict with torch version, cuda availability, device info
            All values are pure Python types (str, bool, int, float, list, dict)
        """
        try:
            import torch
            
            cuda_available = bool(torch.cuda.is_available())
            
            info = {
                "torch_version": str(torch.__version__),
                "cuda_available": cuda_available,
                "cuda_version": str(torch.version.cuda) if cuda_available else None,
                "device_count": int(torch.cuda.device_count()) if cuda_available else 0,
                "device_name": None,
                "devices": [],
            }
            
            if cuda_available:
                for i in range(torch.cuda.device_count()):
                    props = torch.cuda.get_device_properties(i)
                    info["devices"].append({
                        "index": int(i),
                        "name": str(props.name),
                        "total_memory_gb": float(props.total_memory / (1024**3)),
                        "compute_capability": f"{props.major}.{props.minor}",
                    })
                if info["devices"]:
                    info["device_name"] = info["devices"][0]["name"]
            
            return info
            
        except ImportError as e:
            return {"error": f"PyTorch not available: {str(e)}"}
        except Exception as e:
            return {"error": str(e)}
    
    def check_dependencies(self) -> dict:
        """
        Check if all required dependencies are available in subprocess.
        
        Returns:
            dict with package availability status
        """
        result = {}
        
        packages = [
            ("torch", "torch"),
            ("numpy", "numpy"),
            ("scipy", "scipy"),
            ("pillow", "PIL"),
            ("pyyaml", "yaml"),
        ]
        
        for name, import_name in packages:
            try:
                module = __import__(import_name)
                version = getattr(module, "__version__", "unknown")
                result[name] = {"available": True, "version": version}
            except ImportError as e:
                result[name] = {"available": False, "error": str(e)}
        
        # Check gsplat separately (may not be installed)
        try:
            import gsplat
            result["gsplat"] = {"available": True, "version": getattr(gsplat, "__version__", "unknown")}
        except ImportError:
            result["gsplat"] = {"available": False, "error": "Not installed"}
        
        return result
    
    # ==========================================================================
    # Computation Actions (to be expanded)
    # ==========================================================================
    
    def test_cuda_computation(self, size: int = 1000) -> dict:
        """
        Run a simple CUDA computation test.
        
        Args:
            size: Size of test tensor
            
        Returns:
            dict with test results (all pure Python types)
        """
        try:
            import torch
            import time
            
            device = "cuda" if torch.cuda.is_available() else "cpu"
            
            # Create tensors
            start = time.time()
            a = torch.randn(size, size, device=device)
            b = torch.randn(size, size, device=device)
            
            # Matrix multiplication
            c = torch.matmul(a, b)
            
            # Synchronize if CUDA
            if device == "cuda":
                torch.cuda.synchronize()
            
            compute_elapsed = time.time() - start
            
            # Transfer to CPU and convert to Python float
            transfer_start = time.time()
            result_sum = float(c.sum().cpu().item())
            transfer_elapsed = time.time() - transfer_start
            
            return {
                "success": True,
                "device": str(device),
                "size": int(size),
                "compute_time_ms": float(compute_elapsed * 1000),
                "transfer_time_ms": float(transfer_elapsed * 1000),
                "result_sum": result_sum,
            }
            
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    # ==========================================================================
    # SharedMemory IPC Actions (Phase 4)
    # ==========================================================================
    
    # Class-level storage for shared buffer (subprocess side)
    _shared_buffer = None
    _current_gaussians_tensor = None
    
    def setup_shared_buffer(self, buffer_name: str, max_gaussians: int = 100000) -> dict:
        """
        Attach to shared memory buffer created by main process.
        
        Args:
            buffer_name: Name of existing SharedMemory
            max_gaussians: Maximum gaussians supported
            
        Returns:
            dict with status
        """
        try:
            from .shared_buffer import GaussianSharedBuffer
            
            # Attach to existing shared memory
            NPRGenerator._shared_buffer = GaussianSharedBuffer(
                max_gaussians=max_gaussians,
                name=buffer_name
            )
            
            return {
                "success": True,
                "name": buffer_name,
                "max_gaussians": max_gaussians
            }
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def sync_gaussians_from_shared(self, start_idx: int = 0, count: int = None) -> dict:
        """
        Read gaussians from shared memory and convert to PyTorch tensor.
        
        This is called after main process writes to SharedMemory.
        Data is already in memory - just read and convert to tensor.
        
        Args:
            start_idx: Starting index in buffer
            count: Number of gaussians (None = read from header)
            
        Returns:
            dict with sync status
        """
        try:
            import torch
            import time
            
            if NPRGenerator._shared_buffer is None:
                return {"success": False, "error": "SharedBuffer not initialized"}
            
            start = time.perf_counter()
            
            # Zero-copy read from shared memory (returns view)
            gaussians_np = NPRGenerator._shared_buffer.read(start_idx, count)
            actual_count = gaussians_np.shape[0]
            
            read_time = time.perf_counter() - start
            
            # Convert to PyTorch tensor (this copies to GPU)
            start = time.perf_counter()
            device = "cuda" if torch.cuda.is_available() else "cpu"
            NPRGenerator._current_gaussians_tensor = torch.from_numpy(
                gaussians_np.copy()  # Copy needed for tensor creation
            ).to(device)
            
            if device == "cuda":
                torch.cuda.synchronize()
            
            tensor_time = time.perf_counter() - start
            
            return {
                "success": True,
                "count": int(actual_count),
                "device": device,
                "read_time_ms": float(read_time * 1000),
                "tensor_time_ms": float(tensor_time * 1000),
            }
            
        except Exception as e:
            import traceback
            return {"success": False, "error": str(e), "traceback": traceback.format_exc()}
    
    def compute_deformation_shared(self, spline_points: list, deformation_radius: float = 0.5) -> dict:
        """
        Compute spline deformation on current gaussians and write back to SharedMemory.
        
        Args:
            spline_points: List of (x, y, z) tuples for spline
            deformation_radius: Radius of deformation influence
            
        Returns:
            dict with computation status
        """
        try:
            import torch
            import time
            
            if NPRGenerator._current_gaussians_tensor is None:
                return {"success": False, "error": "No gaussians loaded. Call sync_gaussians_from_shared first."}
            
            if NPRGenerator._shared_buffer is None:
                return {"success": False, "error": "SharedBuffer not initialized"}
            
            start = time.perf_counter()
            
            gaussians = NPRGenerator._current_gaussians_tensor
            device = gaussians.device
            
            # Convert spline points to tensor
            spline_tensor = torch.tensor(spline_points, dtype=torch.float32, device=device)
            
            # Simple deformation: Pull gaussians toward spline
            # This is a placeholder - actual deformation uses deformation_gpu.py
            positions = gaussians[:, :3]  # First 3 floats are position
            
            # For each gaussian, find closest point on spline and apply deformation
            # (Simplified version - full implementation in deformation_gpu.py)
            
            compute_time = time.perf_counter() - start
            
            # Write deformed gaussians back to shared memory
            start = time.perf_counter()
            deformed_np = gaussians.cpu().numpy()
            NPRGenerator._shared_buffer.write(deformed_np, start_idx=0)
            write_time = time.perf_counter() - start
            
            return {
                "success": True,
                "count": int(gaussians.shape[0]),
                "compute_time_ms": float(compute_time * 1000),
                "write_time_ms": float(write_time * 1000),
            }
            
        except Exception as e:
            import traceback
            return {"success": False, "error": str(e), "traceback": traceback.format_exc()}
    
    def cleanup_shared_buffer(self) -> dict:
        """
        Cleanup shared buffer resources in subprocess.
        
        Returns:
            dict with cleanup status
        """
        try:
            if NPRGenerator._shared_buffer is not None:
                NPRGenerator._shared_buffer.cleanup()
                NPRGenerator._shared_buffer = None
            
            NPRGenerator._current_gaussians_tensor = None
            
            return {"success": True}
        except Exception as e:
            return {"success": False, "error": str(e)}


# =============================================================================
# Utility Functions
# =============================================================================

def kill_generator():
    """Kill the generator subprocess if running."""
    NPRGenerator.shared_close()


def get_generator() -> NPRGenerator:
    """Get or create the shared NPRGenerator instance."""
    return NPRGenerator.shared()
